# """enhance"""

# import requests
# import json
# import time
# import os
# from datetime import datetime
# from bs4 import BeautifulSoup
# import re

# class LeetCodeSpider:
#     def __init__(self):
#         self.graphql_url = "https://leetcode.cn/graphql/"
#         self.headers = {
#             'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
#             'Content-Type': 'application/json',
#             'Referer': 'https://leetcode.cn/problemset/',
#             'Origin': 'https://leetcode.cn',
#             'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
#         }
#         self.session = requests.Session()
#         self.session.headers.update(self.headers)
#         self.problems_data = []

#     def graphql_query(self, query, variables=None, max_retries=3):
#         """æ‰§è¡ŒGraphQLæŸ¥è¯¢"""
#         payload = {
#             "query": query,
#             "variables": variables or {}
#         }
        
#         for attempt in range(max_retries):
#             try:
#                 response = self.session.post(
#                     self.graphql_url,
#                     json=payload,
#                     timeout=15
#                 )
                
#                 if response.status_code == 200:
#                     return True, response.json()
#                 else:
#                     print(f"GraphQLè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}ï¼Œç¬¬{attempt+1}æ¬¡é‡è¯•")
#                     if attempt < max_retries - 1:
#                         time.sleep(2)
#                         continue
#                     return False, None
                    
#             except Exception as e:
#                 print(f"GraphQLè¯·æ±‚å¼‚å¸¸: {e}ï¼Œç¬¬{attempt+1}æ¬¡é‡è¯•")
#                 if attempt < max_retries - 1:
#                     time.sleep(2)
#                     continue
#                 return False, None
        
#         return False, None

#     def get_problems_list(self, limit=10):
#         """è·å–é¢˜ç›®åˆ—è¡¨"""
#         print(f"è·å–LeetCodeå‰{limit}é“é¢˜ç›®åˆ—è¡¨...")
        
#         query = """
#         query problemsetQuestionList($categorySlug: String, $limit: Int, $skip: Int, $filters: QuestionListFilterInput) {
#           problemsetQuestionList(
#             categorySlug: $categorySlug
#             limit: $limit
#             skip: $skip
#             filters: $filters
#           ) {
#             total
#             questions {
#               acRate
#               difficulty
#               frontendQuestionId
#               isFavor
#               paidOnly
#               status
#               title
#               titleCn
#               titleSlug
#               topicTags {
#                 name
#                 nameTranslated
#                 slug
#               }
#             }
#           }
#         }
#         """
        
#         variables = {
#             "categorySlug": "",
#             "skip": 0,
#             "limit": limit,
#             "filters": {}
#         }
        
#         success, data = self.graphql_query(query, variables)
#         if success and data:
#             questions = data.get('data', {}).get('problemsetQuestionList', {}).get('questions', [])
#             print(f"æˆåŠŸè·å– {len(questions)} é“é¢˜ç›®")
#             return questions
#         else:
#             print("è·å–é¢˜ç›®åˆ—è¡¨å¤±è´¥")
#             return []

#     def parse_translated_content(self, translated_content):
#         """è§£ætranslatedContentï¼Œæ‹†åˆ†æˆä¸åŒéƒ¨åˆ†"""
#         if not translated_content:
#             return {
#                 'description': '',
#                 'examples': [],
#                 'constraints': '',
#                 'follow_up': ''
#             }
        
#         soup = BeautifulSoup(translated_content, 'html.parser')
        
#         # æå–æè¿°éƒ¨åˆ†ï¼ˆç¤ºä¾‹ä¹‹å‰çš„æ‰€æœ‰å†…å®¹ï¼‰
#         description_parts = []
#         examples = []
#         constraints = ""
#         follow_up = ""
        
#         current_section = 'description'
        
#         for element in soup.children:
#             if element.name is None:  # è·³è¿‡ç©ºæ–‡æœ¬èŠ‚ç‚¹
#                 continue
                
#             # æ£€æŸ¥æ˜¯å¦æ˜¯ç¤ºä¾‹æ ‡é¢˜
#             if element.name == 'p' and element.find('strong', class_='example'):
#                 current_section = 'example'
#                 example_title = element.get_text().strip()
#                 example_content = []
#                 examples.append({
#                     'title': example_title,
#                     'content': example_content
#                 })
#                 continue
            
#             # æ£€æŸ¥æ˜¯å¦æ˜¯çº¦æŸæ¡ä»¶æ ‡é¢˜
#             if element.name == 'p' and element.find('strong') and 'æç¤º' in element.get_text():
#                 current_section = 'constraints'
#                 constraints_content = []
#                 continue
                
#             # æ£€æŸ¥æ˜¯å¦æ˜¯è¿›é˜¶æ ‡é¢˜
#             if element.name == 'p' and element.find('strong') and 'è¿›é˜¶' in element.get_text():
#                 current_section = 'follow_up'
#                 follow_up_content = []
#                 continue
            
#             # æ ¹æ®å½“å‰éƒ¨åˆ†å¤„ç†å†…å®¹
#             if current_section == 'description':
#                 description_parts.append(element.get_text().strip())
#             elif current_section == 'example' and examples:
#                 # å¤„ç†ç¤ºä¾‹å†…å®¹
#                 if element.name == 'pre':
#                     examples[-1]['content'].append(f"```\n{element.get_text().strip()}\n```")
#                 else:
#                     text = element.get_text().strip()
#                     if text:
#                         examples[-1]['content'].append(text)
#             elif current_section == 'constraints':
#                 if element.name == 'ul':
#                     constraints = element.get_text().strip()
#                 elif element.name == 'p':
#                     text = element.get_text().strip()
#                     if text and not text.startswith('æç¤º'):
#                         constraints_content.append(text)
#             elif current_section == 'follow_up':
#                 text = element.get_text().strip()
#                 if text and not text.startswith('è¿›é˜¶'):
#                     follow_up_content.append(text)
        
#         # å¤„ç†çº¦æŸæ¡ä»¶å†…å®¹
#         if current_section == 'constraints' and 'constraints_content' in locals():
#             constraints = '\n'.join(constraints_content)
        
#         # å¤„ç†è¿›é˜¶å†…å®¹
#         if current_section == 'follow_up' and 'follow_up_content' in locals():
#             follow_up = '\n'.join(follow_up_content)
        
#         # æ¸…ç†ç¤ºä¾‹å†…å®¹
#         cleaned_examples = []
#         for example in examples:
#             content = '\n'.join(example['content'])
#             # æå–è¾“å…¥è¾“å‡º
#             input_match = re.search(r'è¾“å…¥ï¼š\s*(.*?)(?=è¾“å‡ºï¼š|\n|$)', content, re.DOTALL)
#             output_match = re.search(r'è¾“å‡ºï¼š\s*(.*?)(?=è§£é‡Šï¼š|\n|$)', content, re.DOTALL)
#             explanation_match = re.search(r'è§£é‡Šï¼š\s*(.*?)(?=\n|$)', content, re.DOTALL)
            
#             cleaned_examples.append({
#                 'title': example['title'],
#                 'input': input_match.group(1).strip() if input_match else '',
#                 'output': output_match.group(1).strip() if output_match else '',
#                 'explanation': explanation_match.group(1).strip() if explanation_match else '',
#                 'raw_content': content
#             })
        
#         return {
#             'description': '\n'.join(description_parts),
#             'examples': cleaned_examples,
#             'constraints': constraints,
#             'follow_up': follow_up
#         }

#     def get_problem_detail(self, title_slug):
#         """è·å–é¢˜ç›®è¯¦ç»†ä¿¡æ¯"""
#         print(f"è·å–é¢˜ç›®è¯¦æƒ…: {title_slug}")
        
#         query = """
#         query questionData($titleSlug: String!) {
#           question(titleSlug: $titleSlug) {
#             questionId
#             questionFrontendId
#             title
#             titleCn: translatedTitle
#             content
#             translatedContent
#             difficulty
#             categoryTitle
#             topicTags {
#               name
#               nameTranslated: translatedName
#               slug
#             }
#             codeSnippets {
#               lang
#               langSlug
#               code
#             }
#             hints
#             exampleTestcases
#             sampleTestCase
#             jsonExampleTestcases
#             metaData
#             stats
#             similarQuestions
#             companyTagStats
#           }
#         }
#         """
        
#         variables = {"titleSlug": title_slug}
#         success, data = self.graphql_query(query, variables)
        
#         if success and data:
#             question_data = data.get('data', {}).get('question', {})
            
#             # å¦‚æœtranslatedContentä¸ºç©ºï¼Œå°è¯•ä»contentç”ŸæˆåŸºæœ¬ç¿»è¯‘
#             if not question_data.get('translatedContent') and question_data.get('content'):
#                 print(f"é¢˜ç›® {title_slug} çš„translatedContentä¸ºç©ºï¼Œä½¿ç”¨è‹±æ–‡å†…å®¹")
#                 question_data['translatedContent'] = self.translate_content_basic(question_data['content'])
            
#             # å¦‚æœjsonExampleTestcasesä¸ºç©ºä½†exampleTestcaseså­˜åœ¨ï¼Œå°è¯•è½¬æ¢
#             if not question_data.get('jsonExampleTestcases') and question_data.get('exampleTestcases'):
#                 question_data['jsonExampleTestcases'] = self.convert_to_json_examples(question_data['exampleTestcases'])
            
#             # è§£ætranslatedContent
#             if question_data.get('translatedContent'):
#                 parsed_content = self.parse_translated_content(question_data['translatedContent'])
#                 question_data.update(parsed_content)
            
#             return question_data
#         else:
#             print(f"è·å–é¢˜ç›® {title_slug} è¯¦æƒ…å¤±è´¥")
#             return {}

#     def translate_content_basic(self, content):
#         """åŸºç¡€çš„å†…å®¹ç¿»è¯‘ï¼ˆå…³é”®è¯æ›¿æ¢ï¼‰"""
#         if not content:
#             return ""
        
#         translation_map = {
#             'Example 1:': 'ç¤ºä¾‹ 1:',
#             'Example 2:': 'ç¤ºä¾‹ 2:',
#             'Example 3:': 'ç¤ºä¾‹ 3:',
#             'Input:': 'è¾“å…¥:',
#             'Output:': 'è¾“å‡º:',
#             'Explanation:': 'è§£é‡Š:',
#             'Constraints:': 'çº¦æŸæ¡ä»¶:',
#             'Follow-up:': 'è¿›é˜¶:',
#             'Note:': 'æ³¨æ„:',
#             'æç¤ºï¼š': 'æç¤º:',
#             'æç¤º:': 'æç¤º:',
#         }
        
#         translated = content
#         for eng, cn in translation_map.items():
#             translated = translated.replace(eng, cn)
        
#         return translated

#     def convert_to_json_examples(self, examples):
#         """å°†ç¤ºä¾‹è½¬æ¢ä¸ºJSONæ ¼å¼"""
#         try:
#             # å¦‚æœå·²ç»æ˜¯JSONæ ¼å¼ï¼Œç›´æ¥è¿”å›
#             if examples.strip().startswith('['):
#                 return examples
            
#             # å¦åˆ™å°è¯•è½¬æ¢ä¸ºJSONæ•°ç»„æ ¼å¼
#             lines = examples.strip().split('\n')
#             json_examples = []
#             current_example = ""
            
#             for line in lines:
#                 line = line.strip()
#                 if line:
#                     if current_example:
#                         current_example += "\\n" + line
#                     else:
#                         current_example = line
            
#             if current_example:
#                 json_examples.append(current_example)
            
#             return json.dumps(json_examples, ensure_ascii=False)
            
#         except Exception as e:
#             print(f"è½¬æ¢ç¤ºä¾‹ä¸ºJSONæ—¶å‡ºé”™: {e}")
#             return examples

#     def parse_stats(self, stats_str):
#         """è§£æç»Ÿè®¡ä¿¡æ¯"""
#         try:
#             return json.loads(stats_str)
#         except:
#             return {}

#     def crawl_problems(self, problem_count=10, output_file=None):
#         """çˆ¬å–é¢˜ç›®ä¿¡æ¯"""
#         print(f"å¼€å§‹çˆ¬å– LeetCode å‰ {problem_count} é“é¢˜ç›®...")
#         print("=" * 60)
        
#         # è·å–é¢˜ç›®åˆ—è¡¨
#         problems = self.get_problems_list(problem_count)
        
#         if not problems:
#             print("æœªè·å–åˆ°é¢˜ç›®åˆ—è¡¨")
#             return None
        
#         # è·å–æ¯ä¸ªé¢˜ç›®çš„è¯¦ç»†ä¿¡æ¯
#         for i, problem in enumerate(problems, 1):
#             print(f"\n[{i}/{len(problems)}] å¤„ç†é¢˜ç›®: {problem.get('titleCn', problem.get('title'))}")
            
#             title_slug = problem.get('titleSlug')
#             if not title_slug:
#                 print("è·³è¿‡: æ— titleSlug")
#                 continue
                
#             detail = self.get_problem_detail(title_slug)
            
#             # åˆå¹¶åŸºæœ¬ä¿¡æ¯ä¸è¯¦ç»†ä¿¡æ¯
#             problem_info = {
#                 # # é¢˜ç›®åŸºæœ¬ä¿¡æ¯
#                 # 'questionFrontendId': problem.get('frontendQuestionId'),
#                 # 'title': problem.get('title'),
#                 # 'titleCn': problem.get('titleCn'),
#                 # 'titleSlug': title_slug,
#                 # 'difficulty': problem.get('difficulty'),
#                 # 'acRate': round(problem.get('acRate', 0), 2),
#                 # 'paidOnly': problem.get('paidOnly', False),
                
#                 # é¢˜ç›®è¯¦ç»†ä¿¡æ¯
#                 'question': {
#                     # 'questionId': detail.get('questionId'),
#                     # 'questionFrontendId': detail.get('questionFrontendId'),
#                     # 'title': detail.get('title'),
#                     'translatedTitle': detail.get('titleCn'),
#                     # 'content': detail.get('content'),
#                     # 'translatedContent': detail.get('translatedContent'),  # ä¿ç•™åŸå§‹HTMLå†…å®¹
#                     'description': detail.get('description', ''),  # çº¯æ–‡æœ¬æè¿°
#                     'examples': detail.get('examples', []),  # ç»“æ„åŒ–çš„ç¤ºä¾‹
#                     'constraints': detail.get('constraints', ''),  # çº¦æŸæ¡ä»¶
#                     'followUp': detail.get('follow_up', ''),  # è¿›é˜¶å†…å®¹
#                     'difficulty': detail.get('difficulty'),
#                     # 'categoryTitle': detail.get('categoryTitle'),
#                     'topicTags': detail.get('topicTags', []),
#                     # 'codeSnippets': detail.get('codeSnippets', []),
#                     'hints': detail.get('hints', []),
#                     'exampleTestcases': detail.get('exampleTestcases'),
#                     'sampleTestCase': detail.get('sampleTestCase'),
#                     'jsonExampleTestcases': detail.get('jsonExampleTestcases'),
#                     # 'metaData': detail.get('metaData'),
#                     # 'similarQuestions': detail.get('similarQuestions', []),
#                     # 'companyTagStats': detail.get('companyTagStats'),
#                 },
                
#                 # ç»Ÿè®¡ä¿¡æ¯
#                 # 'stats': self.parse_stats(detail.get('stats', '{}')),
                
#                 # URL
#                 'url': f"https://leetcode.cn/problems/{title_slug}/"
#             }
            
#             self.problems_data.append(problem_info)
#             # print(f"âœ“ å®Œæˆ: {problem_info['titleCn']}")
            
#             # æ·»åŠ å»¶è¿Ÿ
#             if i < len(problems):
#                 delay = 2
#                 print(f"ç­‰å¾… {delay} ç§’...")
#                 time.sleep(delay)
        
#         print(f"\nçˆ¬å–å®Œæˆï¼å…±è·å– {len(self.problems_data)} é“é¢˜ç›®ä¿¡æ¯")
        
#         # ä¿å­˜ä¸ºJSONæ–‡ä»¶
#         if self.problems_data:
#             return self.save_to_json(output_file)
#         else:
#             print("æœªè·å–åˆ°ä»»ä½•é¢˜ç›®æ•°æ®")
#             return None

#     def save_to_json(self, filename=None):
#         """ä¿å­˜æ•°æ®åˆ°JSONæ–‡ä»¶"""
#         if not filename:
#             timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
#             filename = f'leetcode_parsed_{timestamp}.json'
        
#         try:
#             output_data = {
#                 'metadata': {
#                     'source': 'LeetCode GraphQL API',
#                     'crawl_time': datetime.now().isoformat(),
#                     'total_problems': len(self.problems_data),
#                     'version': '2.0'
#                 },
#                 'problems': self.problems_data
#             }
            
#             with open(filename, 'w', encoding='utf-8') as f:
#                 json.dump(output_data, f, ensure_ascii=False, indent=2)
            
#             file_size = os.path.getsize(filename)
#             file_path = os.path.abspath(filename)
            
#             print(f"æ•°æ®å·²ä¿å­˜åˆ°: {file_path}")
#             print(f"æ–‡ä»¶å¤§å°: {file_size} å­—èŠ‚")
            
#             # æ˜¾ç¤ºè¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
#             self.show_detailed_statistics()
            
#             return file_path
            
#         except Exception as e:
#             print(f"ä¿å­˜JSONæ–‡ä»¶æ—¶å‡ºé”™: {e}")
#             return None

#     def show_detailed_statistics(self):
#         """æ˜¾ç¤ºè¯¦ç»†ç»Ÿè®¡ä¿¡æ¯"""
#         print("\nçˆ¬å–ç»Ÿè®¡:")
#         print("=" * 50)
        
#         total = len(self.problems_data)
        
#         # ç»Ÿè®¡å„å­—æ®µçš„å®Œæ•´æ€§
#         fields_to_check = [
#             ('translatedTitle', 'ä¸­æ–‡æ ‡é¢˜'),
#             ('description', 'æè¿°'),
#             ('examples', 'ç¤ºä¾‹'),
#             ('constraints', 'çº¦æŸæ¡ä»¶'),
#             ('followUp', 'è¿›é˜¶'),
#             ('hints', 'æç¤º'),
#             ('codeSnippets', 'ä»£ç ç‰‡æ®µ')
#         ]
        
#         print("å­—æ®µå®Œæ•´æ€§ç»Ÿè®¡:")
#         for field, description in fields_to_check:
#             count = 0
#             for problem in self.problems_data:
#                 question_data = problem.get('question', {})
#                 field_data = question_data.get(field)
#                 if field_data:
#                     if isinstance(field_data, list):
#                         if len(field_data) > 0:
#                             count += 1
#                     elif isinstance(field_data, str):
#                         if field_data.strip():
#                             count += 1
#                     else:
#                         count += 1
            
#             percentage = (count / total) * 100
#             print(f"  {description}: {count}/{total} ({percentage:.1f}%)")
        
#         # éš¾åº¦åˆ†å¸ƒ
#         difficulties = {}
#         for problem in self.problems_data:
#             diff = problem.get('difficulty', 'Unknown')
#             difficulties[diff] = difficulties.get(diff, 0) + 1
        
#         print(f"\néš¾åº¦åˆ†å¸ƒ:")
#         for diff, count in difficulties.items():
#             print(f"  {diff}: {count} é¢˜")
        
#         # æ˜¾ç¤ºç¬¬ä¸€é¢˜çš„è¯¦ç»†è§£æç»“æœ
#         if self.problems_data:
#             print("\nç¬¬ä¸€é¢˜è§£æç»“æœç¤ºä¾‹:")
#             print("=" * 50)
#             first_problem = self.problems_data[0]
#             question = first_problem.get('question', {})
            
#             print(f"æ ‡é¢˜: {question.get('translatedTitle', first_problem.get('titleCn'))}")
#             print(f"éš¾åº¦: {first_problem.get('difficulty')}")
#             print(f"\næè¿°:")
#             print(question.get('description', '')[:200] + "..." if question.get('description') else "æ— ")
            
#             print(f"\nç¤ºä¾‹:")
#             examples = question.get('examples', [])
#             for i, example in enumerate(examples, 1):
#                 print(f"  ç¤ºä¾‹ {i}:")
#                 print(f"    è¾“å…¥: {example.get('input', '')}")
#                 print(f"    è¾“å‡º: {example.get('output', '')}")
#                 print(f"    è§£é‡Š: {example.get('explanation', '')}")
            
#             print(f"\nçº¦æŸæ¡ä»¶:")
#             print(question.get('constraints', 'æ— '))
            
#             print(f"\nè¿›é˜¶:")
#             print(question.get('followUp', 'æ— '))

# def main():
#     """ä¸»å‡½æ•°"""
#     spider = LeetCodeSpider()
    
#     try:
#         output_file = spider.crawl_problems(problem_count=10)
        
#         if output_file:
#             print(f"\nğŸ‰ çˆ¬å–å®Œæˆï¼æ•°æ®å·²ä¿å­˜åˆ°: {output_file}")
#         else:
#             print("\nâŒ çˆ¬å–å¤±è´¥")
            
#     except KeyboardInterrupt:
#         print("\n\nâš ï¸ ç”¨æˆ·ä¸­æ–­çˆ¬å–")
#     except Exception as e:
#         print(f"\nâŒ çˆ¬å–è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
#         import traceback
#         traceback.print_exc()

# if __name__ == "__main__":
#     main()


import random
import requests
import json
import time
import os
from datetime import datetime
from bs4 import BeautifulSoup
import re


class LeetCodeSpider:
    def __init__(self):
        self.graphql_url = "https://leetcode.cn/graphql/"
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Referer': 'https://leetcode.cn/problemset/',
            'Origin': 'https://leetcode.cn',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
        }
        self.session = requests.Session()
        self.session.headers.update(self.headers)
        self.problems_data = []

    def graphql_query(self, query, variables=None, max_retries=3):
        """æ‰§è¡ŒGraphQLæŸ¥è¯¢"""
        payload = {
            "query": query,
            "variables": variables or {}
        }
        
        for attempt in range(max_retries):
            try:
                response = self.session.post(
                    self.graphql_url,
                    json=payload,
                    timeout=15
                )
                
                if response.status_code == 200:
                    return True, response.json()
                else:
                    print(f"GraphQLè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}ï¼Œç¬¬{attempt+1}æ¬¡é‡è¯•")
                    if attempt < max_retries - 1:
                        time.sleep(2)
                        continue
                    return False, None
                    
            except Exception as e:
                print(f"GraphQLè¯·æ±‚å¼‚å¸¸: {e}ï¼Œç¬¬{attempt+1}æ¬¡é‡è¯•")
                if attempt < max_retries - 1:
                    time.sleep(2)
                    continue
                return False, None
        
        return False, None

    def get_problems_list(self, limit=10):
        """è·å–é¢˜ç›®åˆ—è¡¨"""
        print(f"è·å–LeetCodeå‰{limit}é“é¢˜ç›®åˆ—è¡¨...")
        
        query = """
        query problemsetQuestionList($categorySlug: String, $limit: Int, $skip: Int, $filters: QuestionListFilterInput) {
          problemsetQuestionList(
            categorySlug: $categorySlug
            limit: $limit
            skip: $skip
            filters: $filters
          ) {
            total
            questions {
              acRate
              difficulty
              frontendQuestionId
              isFavor
              paidOnly
              status
              title
              titleCn
              titleSlug
              topicTags {
                name
                nameTranslated
                slug
              }
            }
          }
        }
        """
        
        variables = {
            "categorySlug": "",
            "skip": 0,
            "limit": limit,
            "filters": {}
        }
        
        success, data = self.graphql_query(query, variables)
        if success and data:
            questions = data.get('data', {}).get('problemsetQuestionList', {}).get('questions', [])
            print(f"æˆåŠŸè·å– {len(questions)} é“é¢˜ç›®")
            return questions
        else:
            print("è·å–é¢˜ç›®åˆ—è¡¨å¤±è´¥")
            return []

    def parse_translated_content(self, translated_content):
        """è§£ætranslatedContentï¼Œæ‹†åˆ†æˆä¸åŒéƒ¨åˆ†"""
        if not translated_content:
            return {
                'description': '',
                'examples': [],
                'constraints': '',
                'follow_up': ''
            }
        
        soup = BeautifulSoup(translated_content, 'html.parser')
        
        # æå–æè¿°éƒ¨åˆ†ï¼ˆç¤ºä¾‹ä¹‹å‰çš„æ‰€æœ‰å†…å®¹ï¼‰
        description_parts = []
        examples = []
        constraints = ""
        follow_up = ""
        
        # é¦–å…ˆæå–æ‰€æœ‰æ–‡æœ¬å†…å®¹ï¼Œç”¨äºåˆ†æç»“æ„
        all_text = soup.get_text()
        
        # æŸ¥æ‰¾ç¤ºä¾‹éƒ¨åˆ† - ä½¿ç”¨å¤šç§æ–¹æ³•
        example_patterns = [
            r'ç¤ºä¾‹\s*\d+[ï¼š:]?(.*?)(?=ç¤ºä¾‹\s*\d+|çº¦æŸ|æç¤º|è¿›é˜¶|$)',
            r'ç¤ºä¾‹\s*\d+[ï¼š:]?(.*?)(?=ç¤ºä¾‹|çº¦æŸ|æç¤º|è¿›é˜¶|$)',
            r'ç¤ºä¾‹\s*\d+[ï¼š:]?(.*)'
        ]
        
        # æ–¹æ³•1: ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æŸ¥æ‰¾ç¤ºä¾‹
        for pattern in example_patterns:
            example_matches = re.findall(pattern, all_text, re.DOTALL)
            if example_matches:
                for i, match in enumerate(example_matches):
                    if match.strip():
                        # å°è¯•ä»ç¤ºä¾‹æ–‡æœ¬ä¸­æå–è¾“å…¥ã€è¾“å‡ºå’Œè§£é‡Š
                        example_text = match.strip()
                        input_match = re.search(r'è¾“å…¥[ï¼š:]\s*(.*?)(?=è¾“å‡º|è§£é‡Š|$)', example_text, re.DOTALL)
                        output_match = re.search(r'è¾“å‡º[ï¼š:]\s*(.*?)(?=è§£é‡Š|è¾“å…¥|$)', example_text, re.DOTALL)
                        explanation_match = re.search(r'è§£é‡Š[ï¼š:]\s*(.*?)(?=è¾“å…¥|è¾“å‡º|$)', example_text, re.DOTALL)
                        
                        examples.append({
                            'title': f"ç¤ºä¾‹ {i+1}",
                            'input': input_match.group(1).strip() if input_match else '',
                            'output': output_match.group(1).strip() if output_match else '',
                            'explanation': explanation_match.group(1).strip() if explanation_match else '',
                            'raw_content': example_text
                        })
                break
        
        # æ–¹æ³•2: å¦‚æœæ­£åˆ™æ²¡æ‰¾åˆ°ï¼Œå°è¯•ä½¿ç”¨BeautifulSoupæŸ¥æ‰¾ç¤ºä¾‹
        if not examples:
            # æŸ¥æ‰¾åŒ…å«"ç¤ºä¾‹"çš„å…ƒç´ 
            example_elements = soup.find_all(string=re.compile(r'ç¤ºä¾‹\s*\d+'))
            for example_element in example_elements:
                example_title = example_element.strip()
                # è·å–ç¤ºä¾‹å†…å®¹ - å¯èƒ½æ˜¯ä¸‹ä¸€ä¸ªå…ƒç´ æˆ–çˆ¶å…ƒç´ çš„åç»­å…ƒç´ 
                example_content = ""
                
                # å°è¯•è·å–ä¸‹ä¸€ä¸ªå…„å¼Ÿå…ƒç´ 
                next_element = example_element.next_element
                while next_element and next_element.name != 'p' and not re.search(r'ç¤ºä¾‹\s*\d+|çº¦æŸ|æç¤º|è¿›é˜¶', str(next_element)):
                    if next_element.name == 'pre':
                        example_content = next_element.get_text().strip()
                        break
                    next_element = next_element.next_element
                
                if example_content:
                    examples.append({
                        'title': example_title,
                        'input': '',
                        'output': '',
                        'explanation': '',
                        'raw_content': example_content
                    })
        
        # æ–¹æ³•3: æŸ¥æ‰¾æ‰€æœ‰çš„preæ ‡ç­¾ä½œä¸ºç¤ºä¾‹
        if not examples:
            pre_elements = soup.find_all('pre')
            for i, pre in enumerate(pre_elements):
                pre_text = pre.get_text().strip()
                if pre_text and len(pre_text) > 5:  # ç¡®ä¿ä¸æ˜¯ç©ºå†…å®¹
                    examples.append({
                        'title': f"ç¤ºä¾‹ {i+1}",
                        'input': pre_text,
                        'output': '',
                        'explanation': '',
                        'raw_content': pre_text
                    })
        
        # æå–çº¦æŸæ¡ä»¶
        constraints_match = re.search(r'æç¤º[ï¼š:]\s*(.*?)(?=è¿›é˜¶|$)', all_text, re.DOTALL)
        if constraints_match:
            constraints = constraints_match.group(1).strip()
        else:
            # å°è¯•æŸ¥æ‰¾ulåˆ—è¡¨ä½œä¸ºçº¦æŸæ¡ä»¶
            ul_elements = soup.find_all('ul')
            for ul in ul_elements:
                prev_text = ul.find_previous().get_text() if ul.find_previous() else ""
                if 'æç¤º' in prev_text or 'çº¦æŸ' in prev_text:
                    constraints = ul.get_text().strip()
                    break
        
        # æå–è¿›é˜¶å†…å®¹
        follow_up_match = re.search(r'è¿›é˜¶[ï¼š:]\s*(.*?)(?=ç¤ºä¾‹|çº¦æŸ|æç¤º|$)', all_text, re.DOTALL)
        if follow_up_match:
            follow_up = follow_up_match.group(1).strip()
        
        # æå–æè¿°éƒ¨åˆ† - ä»å¼€å§‹åˆ°ç¬¬ä¸€ä¸ªç¤ºä¾‹ä¹‹å‰
        if examples:
            first_example_pos = all_text.find(examples[0]['title'])
            if first_example_pos != -1:
                description = all_text[:first_example_pos].strip()
            else:
                description = all_text
        else:
            description = all_text
        
        # æ¸…ç†æè¿° - ç§»é™¤çº¦æŸå’Œè¿›é˜¶éƒ¨åˆ†
        if constraints:
            constraints_pos = description.find('æç¤º')
            if constraints_pos != -1:
                description = description[:constraints_pos].strip()
        
        if follow_up:
            follow_up_pos = description.find('è¿›é˜¶')
            if follow_up_pos != -1:
                description = description[:follow_up_pos].strip()
        
        return {
            'description': description,
            'examples': examples,
            'constraints': constraints,
            'follow_up': follow_up
        }

    def get_problem_detail(self, title_slug):
        """è·å–é¢˜ç›®è¯¦ç»†ä¿¡æ¯"""
        print(f"è·å–é¢˜ç›®è¯¦æƒ…: {title_slug}")
        
        query = """
        query questionData($titleSlug: String!) {
          question(titleSlug: $titleSlug) {
            questionId
            questionFrontendId
            title
            titleCn: translatedTitle
            content
            translatedContent
            difficulty
            categoryTitle
            topicTags {
              name
              nameTranslated: translatedName
              slug
            }
            codeSnippets {
              lang
              langSlug
              code
            }
            hints
            exampleTestcases
            sampleTestCase
            jsonExampleTestcases
            metaData
            stats
            similarQuestions
            companyTagStats
          }
        }
        """
        
        variables = {"titleSlug": title_slug}
        success, data = self.graphql_query(query, variables)
        
        if success and data:
            question_data = data.get('data', {}).get('question', {})
            
            # å¦‚æœtranslatedContentä¸ºç©ºï¼Œå°è¯•ä»contentç”ŸæˆåŸºæœ¬ç¿»è¯‘
            if not question_data.get('translatedContent') and question_data.get('content'):
                print(f"é¢˜ç›® {title_slug} çš„translatedContentä¸ºç©ºï¼Œä½¿ç”¨è‹±æ–‡å†…å®¹")
                question_data['translatedContent'] = self.translate_content_basic(question_data['content'])
            
            # å¦‚æœjsonExampleTestcasesä¸ºç©ºä½†exampleTestcaseså­˜åœ¨ï¼Œå°è¯•è½¬æ¢
            if not question_data.get('jsonExampleTestcases') and question_data.get('exampleTestcases'):
                question_data['jsonExampleTestcases'] = self.convert_to_json_examples(question_data['exampleTestcases'])
            
            # è§£ætranslatedContent
            if question_data.get('translatedContent'):
                parsed_content = self.parse_translated_content(question_data['translatedContent'])
                question_data.update(parsed_content)
            
            return question_data
        else:
            print(f"è·å–é¢˜ç›® {title_slug} è¯¦æƒ…å¤±è´¥")
            return {}

    def translate_content_basic(self, content):
        """åŸºç¡€çš„å†…å®¹ç¿»è¯‘ï¼ˆå…³é”®è¯æ›¿æ¢ï¼‰"""
        if not content:
            return ""
        
        translation_map = {
            'Example 1:': 'ç¤ºä¾‹ 1:',
            'Example 2:': 'ç¤ºä¾‹ 2:',
            'Example 3:': 'ç¤ºä¾‹ 3:',
            'Input:': 'è¾“å…¥:',
            'Output:': 'è¾“å‡º:',
            'Explanation:': 'è§£é‡Š:',
            'Constraints:': 'çº¦æŸæ¡ä»¶:',
            'Follow-up:': 'è¿›é˜¶:',
            'Note:': 'æ³¨æ„:',
            'æç¤ºï¼š': 'æç¤º:',
            'æç¤º:': 'æç¤º:',
        }
        
        translated = content
        for eng, cn in translation_map.items():
            translated = translated.replace(eng, cn)
        
        return translated

    def convert_to_json_examples(self, examples):
        """å°†ç¤ºä¾‹è½¬æ¢ä¸ºJSONæ ¼å¼"""
        try:
            # å¦‚æœå·²ç»æ˜¯JSONæ ¼å¼ï¼Œç›´æ¥è¿”å›
            if examples.strip().startswith('['):
                return examples
            
            # å¦åˆ™å°è¯•è½¬æ¢ä¸ºJSONæ•°ç»„æ ¼å¼
            lines = examples.strip().split('\n')
            json_examples = []
            current_example = ""
            
            for line in lines:
                line = line.strip()
                if line:
                    if current_example:
                        current_example += "\\n" + line
                    else:
                        current_example = line
            
            if current_example:
                json_examples.append(current_example)
            
            return json.dumps(json_examples, ensure_ascii=False)
            
        except Exception as e:
            print(f"è½¬æ¢ç¤ºä¾‹ä¸ºJSONæ—¶å‡ºé”™: {e}")
            return examples

    def parse_stats(self, stats_str):
        """è§£æç»Ÿè®¡ä¿¡æ¯"""
        try:
            return json.loads(stats_str)
        except:
            return {}

    def crawl_problems(self, problem_count=10, output_file=None):
        """çˆ¬å–é¢˜ç›®ä¿¡æ¯"""
        print(f"å¼€å§‹çˆ¬å– LeetCode å‰ {problem_count} é“é¢˜ç›®...")
        print("=" * 60)
        
        # è·å–é¢˜ç›®åˆ—è¡¨
        problems = self.get_problems_list(problem_count)
        
        if not problems:
            print("æœªè·å–åˆ°é¢˜ç›®åˆ—è¡¨")
            return None
        
        # è·å–æ¯ä¸ªé¢˜ç›®çš„è¯¦ç»†ä¿¡æ¯
        for i, problem in enumerate(problems, 1):
            print(f"\n[{i}/{len(problems)}] å¤„ç†é¢˜ç›®: {problem.get('titleCn', problem.get('title'))}")
            
            title_slug = problem.get('titleSlug')
            if not title_slug:
                print("è·³è¿‡: æ— titleSlug")
                continue
                
            detail = self.get_problem_detail(title_slug)
            
            # åˆå¹¶åŸºæœ¬ä¿¡æ¯ä¸è¯¦ç»†ä¿¡æ¯
            problem_info = {
                # # é¢˜ç›®åŸºæœ¬ä¿¡æ¯
                # 'questionFrontendId': problem.get('frontendQuestionId'),
                # 'title': problem.get('title'),
                # 'titleCn': problem.get('titleCn'),
                # 'titleSlug': title_slug,
                # 'difficulty': problem.get('difficulty'),
                # 'acRate': round(problem.get('acRate', 0), 2),
                # 'paidOnly': problem.get('paidOnly', False),
                
                # é¢˜ç›®è¯¦ç»†ä¿¡æ¯
                'question': {
                    # 'questionId': detail.get('questionId'),
                    # 'questionFrontendId': detail.get('questionFrontendId'),
                    # 'title': detail.get('title'),
                    'translatedTitle': detail.get('titleCn'),
                    # 'content': detail.get('content'),
                    'translatedContent': detail.get('translatedContent'),  # ä¿ç•™åŸå§‹HTMLå†…å®¹
                    'description': detail.get('description', ''),  # çº¯æ–‡æœ¬æè¿°
                    'examples': detail.get('examples', []),  # ç»“æ„åŒ–çš„ç¤ºä¾‹
                    'constraints': detail.get('constraints', ''),  # çº¦æŸæ¡ä»¶
                    'followUp': detail.get('follow_up', ''),  # è¿›é˜¶å†…å®¹
                    'difficulty': detail.get('difficulty'),
                    # 'categoryTitle': detail.get('categoryTitle'),
                    'topicTags': detail.get('topicTags', []),
                    # 'codeSnippets': detail.get('codeSnippets', []),
                    'hints': detail.get('hints', []),
                    'exampleTestcases': detail.get('exampleTestcases'),
                    'sampleTestCase': detail.get('sampleTestCase'),
                    'jsonExampleTestcases': detail.get('jsonExampleTestcases'),
                    # 'metaData': detail.get('metaData'),
                    # 'similarQuestions': detail.get('similarQuestions', []),
                    # 'companyTagStats': detail.get('companyTagStats'),
                },
                
                # ç»Ÿè®¡ä¿¡æ¯
                # 'stats': self.parse_stats(detail.get('stats', '{}')),
                
                # URL
                # 'url': f"https://leetcode.cn/problems/{title_slug}/"
            }
            
            self.problems_data.append(problem_info)
            
            # æ˜¾ç¤ºç¤ºä¾‹æå–æƒ…å†µ
            # examples_count = len(detail.get('examples', []))
            # if examples_count > 0:
                # print(f"âœ“ å®Œæˆ: {problem_info['titleCn']} (æå–åˆ° {examples_count} ä¸ªç¤ºä¾‹)")
            # else:
                # print(f"âš  å®Œæˆ: {problem_info['titleCn']} (æœªæå–åˆ°ç¤ºä¾‹)")
            
            # æ·»åŠ å»¶è¿Ÿ
            if i < len(problems):
                delay = 5
                print(f"ç­‰å¾… {delay} ç§’...")
                time.sleep(delay)
        
        print(f"\nçˆ¬å–å®Œæˆï¼å…±è·å– {len(self.problems_data)} é“é¢˜ç›®ä¿¡æ¯")
        
        # ä¿å­˜ä¸ºJSONæ–‡ä»¶
        if self.problems_data:
            return self.save_to_json(output_file)
        else:
            print("æœªè·å–åˆ°ä»»ä½•é¢˜ç›®æ•°æ®")
            return None

    def save_to_json(self, filename=None):
        """ä¿å­˜æ•°æ®åˆ°JSONæ–‡ä»¶"""
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f'leetcode_improved_{timestamp}.json'
        
        try:
            output_data = {
                'metadata': {
                    'source': 'LeetCode GraphQL API',
                    'crawl_time': datetime.now().isoformat(),
                    'total_problems': len(self.problems_data),
                    'version': '3.0'
                },
                'problems': self.problems_data
            }
            
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(output_data, f, ensure_ascii=False, indent=2)
            
            file_size = os.path.getsize(filename)
            file_path = os.path.abspath(filename)
            
            print(f"æ•°æ®å·²ä¿å­˜åˆ°: {file_path}")
            print(f"æ–‡ä»¶å¤§å°: {file_size} å­—èŠ‚")
            
            # æ˜¾ç¤ºè¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
            self.show_detailed_statistics()
            
            return file_path
            
        except Exception as e:
            print(f"ä¿å­˜JSONæ–‡ä»¶æ—¶å‡ºé”™: {e}")
            return None

    def show_detailed_statistics(self):
        """æ˜¾ç¤ºè¯¦ç»†ç»Ÿè®¡ä¿¡æ¯"""
        print("\nçˆ¬å–ç»Ÿè®¡:")
        print("=" * 50)
        
        total = len(self.problems_data)
        
        # ç»Ÿè®¡å„å­—æ®µçš„å®Œæ•´æ€§
        fields_to_check = [
            ('translatedTitle', 'ä¸­æ–‡æ ‡é¢˜'),
            ('description', 'æè¿°'),
            ('examples', 'ç¤ºä¾‹'),
            ('constraints', 'çº¦æŸæ¡ä»¶'),
            ('followUp', 'è¿›é˜¶'),
            ('hints', 'æç¤º'),
            ('codeSnippets', 'ä»£ç ç‰‡æ®µ')
        ]
        
        print("å­—æ®µå®Œæ•´æ€§ç»Ÿè®¡:")
        for field, description in fields_to_check:
            count = 0
            for problem in self.problems_data:
                question_data = problem.get('question', {})
                field_data = question_data.get(field)
                if field_data:
                    if isinstance(field_data, list):
                        if len(field_data) > 0:
                            count += 1
                    elif isinstance(field_data, str):
                        if field_data.strip():
                            count += 1
                    else:
                        count += 1
            
            percentage = (count / total) * 100
            print(f"  {description}: {count}/{total} ({percentage:.1f}%)")
        
        # ç¤ºä¾‹ç»Ÿè®¡
        examples_stats = [0, 0, 0, 0]  # 0ä¸ª, 1ä¸ª, 2ä¸ª, 3+ä¸ªç¤ºä¾‹
        for problem in self.problems_data:
            examples_count = len(problem.get('question', {}).get('examples', []))
            if examples_count >= 3:
                examples_stats[3] += 1
            elif examples_count == 2:
                examples_stats[2] += 1
            elif examples_count == 1:
                examples_stats[1] += 1
            else:
                examples_stats[0] += 1
        
        print(f"\nç¤ºä¾‹æ•°é‡åˆ†å¸ƒ:")
        print(f"  æ— ç¤ºä¾‹: {examples_stats[0]} é¢˜")
        print(f"  1ä¸ªç¤ºä¾‹: {examples_stats[1]} é¢˜")
        print(f"  2ä¸ªç¤ºä¾‹: {examples_stats[2]} é¢˜")
        print(f"  3+ä¸ªç¤ºä¾‹: {examples_stats[3]} é¢˜")
        
        # éš¾åº¦åˆ†å¸ƒ
        difficulties = {}
        for problem in self.problems_data:
            diff = problem.get('difficulty', 'Unknown')
            difficulties[diff] = difficulties.get(diff, 0) + 1
        
        print(f"\néš¾åº¦åˆ†å¸ƒ:")
        for diff, count in difficulties.items():
            print(f"  {diff}: {count} é¢˜")
        
        # æ˜¾ç¤ºç¬¬ä¸€é¢˜çš„è¯¦ç»†è§£æç»“æœ
        if self.problems_data:
            print("\nç¬¬ä¸€é¢˜è§£æç»“æœç¤ºä¾‹:")
            print("=" * 50)
            first_problem = self.problems_data[0]
            question = first_problem.get('question', {})
            
            print(f"æ ‡é¢˜: {question.get('translatedTitle', first_problem.get('titleCn'))}")
            print(f"éš¾åº¦: {first_problem.get('difficulty')}")
            print(f"\næè¿°:")
            desc = question.get('description', '')
            print(desc[:200] + "..." if len(desc) > 200 else desc or "æ— ")
            
            print(f"\nç¤ºä¾‹:")
            examples = question.get('examples', [])
            if examples:
                for i, example in enumerate(examples, 1):
                    print(f"  ç¤ºä¾‹ {i}:")
                    if example.get('input'):
                        print(f"    è¾“å…¥: {example.get('input', '')}")
                    if example.get('output'):
                        print(f"    è¾“å‡º: {example.get('output', '')}")
                    if example.get('explanation'):
                        print(f"    è§£é‡Š: {example.get('explanation', '')}")
                    if example.get('raw_content') and not (example.get('input') or example.get('output')):
                        print(f"    å†…å®¹: {example.get('raw_content', '')}")
            else:
                print("  æ— ç¤ºä¾‹")
            
            print(f"\nçº¦æŸæ¡ä»¶:")
            print(question.get('constraints', 'æ— '))
            
            print(f"\nè¿›é˜¶:")
            print(question.get('followUp', 'æ— '))

def main():
    """ä¸»å‡½æ•°"""
    spider = LeetCodeSpider()
    
    try:
        output_file = spider.crawl_problems(problem_count=50)
        
        if output_file:
            print(f"\nğŸ‰ çˆ¬å–å®Œæˆï¼æ•°æ®å·²ä¿å­˜åˆ°: {output_file}")
        else:
            print("\nâŒ çˆ¬å–å¤±è´¥")
            
    except KeyboardInterrupt:
        print("\n\nâš ï¸ ç”¨æˆ·ä¸­æ–­çˆ¬å–")
    except Exception as e:
        print(f"\nâŒ çˆ¬å–è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
